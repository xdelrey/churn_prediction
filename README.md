# PredicciÃ³n de *Churn* en Telecom ğŸ“‰ğŸ“±

Proyecto de *Machine Learning*Â para predecir las bajasÂ *(churn)* de clientes en una compaÃ±Ã­a de telecomunicaciones.

> "Adquirir un nuevo cliente es hasta 25â€¯Ã— mÃ¡s caro que retener uno existente." ğŸ¤‘

---

## ğŸŒ Contexto del problema

Detectar con antelaciÃ³n quÃ© clientes abandonarÃ¡n el servicio permite dirigir campaÃ±as de retenciÃ³n y optimizar recursos. El objetivo principal fue **maximizar el *****Recall***** (â‰¥â€¯0.85)** aun sacrificando *Precision*, minimizando asÃ­ los *Falsos Negativos* ğŸ›¡ï¸.

## ğŸ—ƒï¸ Dataset

- Fuente: *WA\_Fnâ€‘UseC\_Telcoâ€‘Customerâ€‘Churn* (IBM) â€“ 7â€¯043 registros Ã—â€¯21 variables.
- InformaciÃ³n demogrÃ¡fica, tipo de contrato, servicios contratados y facturaciÃ³n.
- Variable objetivo: `Churn` (SÃ­/No).

## ğŸ” Proceso de trabajo

1. ExploraciÃ³n inicial & EDA
   - Distribuciones, correlaciones, desequilibrio de clases. ğŸ“Š
2. Limpieza & _Feature Engineering_ ğŸ§¹
   - ConversiÃ³n de binarias y "cuasiâ€‘binarias" a 0/1.
   - AgrupaciÃ³n de categorÃ­as "No internet/phone service" â†’ "No".
   - ConversiÃ³n de `gender` a numÃ©rica.
   - EliminaciÃ³n de `customerID`.
   - NormalizaciÃ³n de variables numÃ©ricas.
   - Manejo de nulos (11 en `TotalCharges` â†’ 0 donde `tenure = 0`).
3. Modelado ğŸ¤–
   - RegresiÃ³n LogÃ­stica (baseline).
   - Randomâ€¯Forest.
   - **XGBoost** (con y sin ajuste de *threshold*).
4. EvaluaciÃ³n
   - *Accuracy*, *Precision*, *Recall*, AUCâ€‘ROC.
   - Ajuste de *threshold* (0.46) para mejorar *Recall*.
5. Despliegue
   - API & demo (Streamlit).

## ğŸ“Š Resultados

| Fecha      | Modelo              | `params` principales                      | Precision | Recall    | Accuracy  | AUC       |
| ---------- | ------------------- | ----------------------------------------- | --------- | --------- | --------- | --------- |
| 2025â€‘07â€‘06 | *Baseline*â€¯(LogReg) | C=10, solver=liblinear                    | **0.477** | 0.784     | 0.738     | 0.843     |
| 2025â€‘07â€‘06 | Randomâ€¯Forest       | max\_depth=10, n\_estimators=600          | **0.545** | 0.729     | **0.786** | **0.848** |
| 2025â€‘07â€‘06 | XGBoost             | lr=0.015, max\_depth=3, n\_estimators=400 | 0.480     | 0.822     | 0.740     | 0.846     |
| 2025â€‘07â€‘06 | XGBoost (thrâ€¯0.46)  | mismo que arriba                          | 0.471     | **0.851** | 0.731     | 0.846     |

> ğŸ“Œ **Tradeâ€‘off**: alcanzar *Recall*â€¯â‰ˆâ€¯0.85 implica *Precision*â€¯â‰ˆâ€¯0.45 (â‰ˆâ€¯55â€¯% falsas alarmas). Debe discutirse con negocio el coste/beneficio de gestionar esas alertas.

## ğŸ“‚ Estructura del repositorio

```text
churn_prediction/
â”œâ”€â”€ app_streamlit/                 # Demo interactiva ğŸ–¥ï¸
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Dataset original
â”‚   â”œâ”€â”€ processed/                 # CSVs limpios & featureâ€‘engineered
â”‚   â””â”€â”€ train/, test/              # Splits
â”œâ”€â”€ models/                        # Modelos .pkl y artefactos
â”œâ”€â”€ notebooks/                    
â”‚   â”œâ”€â”€ 01_Fuentes.ipynb           # Ingesta de datos
â”‚   â”œâ”€â”€ 02_LimpiezaEDA.ipynb       # Limpieza & EDA
â”‚   â””â”€â”€ 03_Entrenamiento_Evaluacion.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ churn_model.py             # Clase predictora
â”‚   â”œâ”€â”€ data_processing.py         # Pipeline de limpieza
â”‚   â”œâ”€â”€ training.py                # Entrenamiento
â”‚   â””â”€â”€ evaluation.py              # MÃ©tricas
â””â”€â”€ README.md                      # (este documento)
```

## ğŸŒ App Demo

- [Streamlit App](https://churn-prediction-cprc.onrender.com/)  

## ğŸ—’ï¸ Pendientes / PrÃ³ximos pasos

- Mejora en el balanceo del _Target_.
- Profundizar en _Feature Engineering_ para disminuir el nÃºmero de _Features_.
- Desarrollar nuevos modelos.

---

### âœï¸ Autor

**Xabi delâ€¯Rey** â€” *Product Manager & Data Science Bootcamper*\
Contacto â†’ [LinkedIn](https://www.linkedin.com/in/xabidelrey/) ğŸ¤
