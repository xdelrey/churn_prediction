# PredicciÃ³n de *Churn* en Telecom ğŸ“‰ğŸ“±

Proyecto de *Machine Learning*Â para predecir las bajasÂ *(churn)* de clientes en una compaÃ±Ã­a de telecomunicaciones.

> "Adquirir un nuevo cliente es hasta 25â€¯Ã— mÃ¡s caro que retener uno existente." ğŸ¤‘

---

## ğŸŒ Contexto del problema

Detectar con antelaciÃ³n quÃ© clientes abandonarÃ¡n el servicio permite dirigir campaÃ±as de retenciÃ³n y optimizar recursos. El objetivo principal fue **maximizar el *****Recall***** (â‰¥â€¯0.85)** aun sacrificando *Precision*, minimizando asÃ­ los *Falsos Negativos* ğŸ›¡ï¸.

## ğŸ—ƒï¸ Dataset

- Fuente: *WA\_Fnâ€‘UseC\_Telcoâ€‘Customerâ€‘Churn* (IBM) â€“ 7â€¯043 registros Ã—â€¯21 variables.
- InformaciÃ³n demogrÃ¡fica, tipo de contrato, servicios contratados y facturaciÃ³n.
- Variable objetivo: `Churn` (SÃ­/No).

## ğŸ” Proceso de trabajo

1. **ExploraciÃ³n inicial & EDA**
   - Distribuciones, correlaciones, desequilibrio de clases. ğŸ“Š
2. \*\*Limpieza & \*\****Feature Engineering*** ğŸ§¹
   - ConversiÃ³n de binarias y cuasiâ€‘binarias a 0/1.
   - AgrupaciÃ³n de categorÃ­as "No internet/phone service" â†’ "No".
   - ConversiÃ³n de `gender` a numÃ©rica.
   - EliminaciÃ³n de `customerID`.
   - NormalizaciÃ³n de variables numÃ©ricas.
   - Manejo de nulos (11 en `TotalCharges` â†’ 0 donde `tenure = 0`).
3. **Modelado** ğŸ¤–
   - **RegresiÃ³n LogÃ­stica** (baseline).
   - **Randomâ€¯Forest**.
   - **XGBoost** (con y sin ajuste de *threshold*).
4. **EvaluaciÃ³n**
   - *Accuracy*, *Precision*, *Recall*, AUCâ€‘ROC.
   - Ajuste de *threshold* (0.46) para mejorar *Recall*.
5. **Despliegue** ğŸš€
   - API & demo en **Streamlit** (`app_streamlit/`).

## ğŸ“Š Resultados

| Fecha      | Modelo              | `params` principales                      | Precision | Recall    | Accuracy  | AUC       |
| ---------- | ------------------- | ----------------------------------------- | --------- | --------- | --------- | --------- |
| 2025â€‘07â€‘06 | *Baseline*â€¯(LogReg) | C=10, solver=liblinear                    | **0.477** | 0.784     | 0.738     | 0.843     |
| 2025â€‘07â€‘06 | Randomâ€¯Forest       | max\_depth=10, n\_estimators=600          | **0.545** | 0.729     | **0.786** | **0.848** |
| 2025â€‘07â€‘06 | XGBoost             | lr=0.015, max\_depth=3, n\_estimators=400 | 0.480     | 0.822     | 0.740     | 0.846     |
| 2025â€‘07â€‘06 | XGBoost (thrâ€¯0.46)  | mismo que arriba                          | 0.471     | **0.851** | 0.731     | 0.846     |

> ğŸ“Œ **Tradeâ€‘off**: alcanzar *Recall*â€¯â‰ˆâ€¯0.85 implica *Precision*â€¯â‰ˆâ€¯0.45 (â‰ˆâ€¯55â€¯% falsas alarmas). Debe discutirse con negocio el coste/beneficio de gestionar esas alertas.

## ğŸ“‚ Estructura del repositorio

```text
churn_prediction/
â”œâ”€â”€ app_streamlit/                 # Demo interactiva ğŸ–¥ï¸
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Dataset original
â”‚   â”œâ”€â”€ processed/                 # CSVs limpios & featureâ€‘engineered
â”‚   â””â”€â”€ train/, test/              # Splits
â”œâ”€â”€ models/                        # Modelos .pkl y artefactos
â”œâ”€â”€ notebooks/                    
â”‚   â”œâ”€â”€ 01_Fuentes.ipynb           # Ingesta de datos
â”‚   â”œâ”€â”€ 02_LimpiezaEDA.ipynb       # Limpieza & EDA
â”‚   â””â”€â”€ 03_Entrenamiento_Evaluacion.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ churn_model.py             # Clase predictora
â”‚   â”œâ”€â”€ data_processing.py         # Pipeline de limpieza
â”‚   â”œâ”€â”€ training.py                # Entrenamiento
â”‚   â””â”€â”€ evaluation.py              # MÃ©tricas & plots
â””â”€â”€ README.md                      # (este documento)
```

## âš™ï¸ InstalaciÃ³n rÃ¡pida

```bash
# 1) Clonar el repo
$ git clone https://github.com/tuâ€‘usuario/churn_prediction.git
$ cd churn_prediction

# 2) Crear entorno (Conda)
$ conda env create -f environment.yml
$ conda activate churnâ€‘ml

# 3) Arrancar la app Streamlit
$ streamlit run app_streamlit/app.py
```

## ğŸš€ Uso en producciÃ³n

```python
from src.churn_model import ChurnModel

model = ChurnModel.load('models/final_model_3_grid_xgb_v5.pkl')
prob = model.predict_proba(cliente)  # devuelve probabilidad de baja
```

## ğŸ—’ï¸ Pendientes / PrÃ³ximos pasos

- Hiperâ€‘ajuste de XGBoost con Optuna.
- *SMOTE* o *ClassÂ Weights* para reequilibrar clases.
- Feature: consumo de streaming, soporte tÃ©cnico, etc.
- IntegraciÃ³n CI/CD y despliegue en Docker/Kubernetes.
- Dashboard de mÃ©tricas para negocio.

---

### âœï¸ Autor

**Xabi delâ€¯Rey** â€” *Product Manager & Data Science Bootcamper*\
Contacto â†’ [LinkedIn](https://www.linkedin.com/in/xabidelrey/) ğŸ¤
